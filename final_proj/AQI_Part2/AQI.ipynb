{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b6978",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"AQI.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c611a37",
   "metadata": {},
   "source": [
    "# Final Project: Air Quality Dataset\n",
    "## Analyzing and Predicting AQI Data through Modeling\n",
    "## Due Date: Thursday, December 17th, 11:59 PM\n",
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with other groups about\n",
    "the project, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others outside of your group please **include their names** at the top\n",
    "of your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299ff619",
   "metadata": {},
   "source": [
    "## This Assignment\n",
    "\n",
    "In this final project, we will investigate AQI data for the year 2020 from **USA EPA** data. All the data used for this project can be accessed from the [EPA Website](https://aqs.epa.gov/aqsweb/airdata/download_files.html), which we will pull from directly in this notebook. This dataset contains geographical and time-series data on various factors that contribute to AQI from all government sites. The main goal at the end for you will be to understand how AQI varies both geographically and over time, and use your analysis (as well as other data that you can find) to be predict AQI at a certain point in time for various locations in California.\n",
    "\n",
    "Through this final project, you will demonstrate your experience with:\n",
    "* EDA and merging on location using Pandas\n",
    "* Unsupervised and supervised learning techniques\n",
    "* Visualization and interpolation\n",
    "\n",
    "This is **part 1** of the project, which includes the data cleaning, guided EDA and open-ended EDA components of the project. This will help you for part 2, where you will be completing the modeling component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e624bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import geopandas as gpd\n",
    "\n",
    "import os\n",
    "import requests, zipfile, io\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f2ec9",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "## Section 1: Data Cleaning\n",
    "\n",
    "As mentioned, we will be using the **US EPA** data from the EPA website. Below is a dataframe of the files we will be using for the project. The following two cells will download the data and put it into a dictionary called `epa_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c875d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_weburl = \"https://aqs.epa.gov/aqsweb/airdata/\"\n",
    "epa_filenames = pd.read_csv(\"data/epa_filenames.csv\")\n",
    "epa_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d5a045",
   "metadata": {},
   "source": [
    "Below is code that we used to extract the code from the AQI website, which we encourage you to understand! This will pull directly from the website urls and put it into your `data/` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45792402",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_data = {}\n",
    "for name, filename in zip(epa_filenames['name'], epa_filenames['epa_filename']):\n",
    "    path_name = 'data/{}'.format(name)\n",
    "    if not os.path.isdir(path_name): \n",
    "        data_url = '{}{}.zip'.format(epa_weburl, filename)\n",
    "        req = requests.get(data_url)\n",
    "        z = zipfile.ZipFile(io.BytesIO(req.content))\n",
    "        z.extractall(path_name)\n",
    "    data = pd.read_csv(f'data/{name}/{filename}.csv')\n",
    "    epa_data[name] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86fef96",
   "metadata": {},
   "source": [
    "Use the below cell to explore each of the datasets, which can be accessed using the keys in the `name` column of `epa_filenames` above. Currently, the cell is viewing the `annual_county_aqi` dataset, but feel free to change it to whichever dataset you want to explore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a83d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_data.get('annual_county_aqi').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e3c82",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 0: Understanding the Data\n",
    "\n",
    "Notice that for the table `annual_county_aqi`, the 90th percentile AQI is reported as a column. Why would the 90th percentile AQI be useful as opposed to the maximum? What does it mean when the difference between the 90th percentile AQI and Max AQI is very large compared to the difference between the 90th percentile AQI and the median AQI?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q0\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a64f72",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81fa62f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 1a: Creating Month and Day Columns\n",
    "\n",
    "In the `daily_county_aqi` table in `epa_data`, add two new columns called `Day` and `Month` that denote the day and month, respectively, of the AQI reading. The day and month should both be reported as an **integer** as opposed to a string (`Jan`, `Feb`, etc.)\n",
    "\n",
    "hint: `pd.to_datetime` may be useful.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3287b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_county = epa_data.get('daily_county_aqi')\n",
    "daily_county['Month'] = ...\n",
    "daily_county['Day'] = ...\n",
    "\n",
    "\n",
    "daily_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fb006",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aac1d3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "### Question 1b: California Data\n",
    "\n",
    "Currently, `epa_data` contains data for **all** counties in the United States. For the guided part of this project, we are specifically going to be focusing on AQI data for counties in California only. Your task is to assign `epa_data_CA` a dictionary mapping table names to dataframes. This map should have the same contents as `epa_data` but only tables that contain **daily data** in the state of `California`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b203093",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_data_CA = {}\n",
    "\n",
    "...\n",
    "    \n",
    "\n",
    "epa_data_CA.get('daily_county_aqi').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff29afa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd789c4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "### Question 1c: Merging Site Information\n",
    "\n",
    "Now take a look at this [link](https://www.epa.gov/outdoor-air-quality-data/about-air-data-reports) and look under \"Site ID\". For later analysis, we want to first get the latitude and longitudes of each of the measurements in the `daily_county_aqi` table by merging two or more tables in `epa_data_CA` (one of the tables is `daily_county_aqi`).\n",
    "\n",
    "Our final merged table should be assigned to `epa_data_CA_merged` and the result should contain the following columns: `State Name`, `county Name`, `Month`, `Day`, `AQI`, `Category`, `Defining Site`, `Latitude`, and `Longitude`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "points: 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be28f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['State Name', 'county Name', 'Month', 'Day', 'AQI', 'Category', 'Defining Site', 'Latitude', 'Longitude']\n",
    "epa_data_CA_merged = ...\n",
    "\n",
    "\n",
    "epa_data_CA_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b3e2aa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934d18f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "### Question 2a - Cleaning Traffic Data \n",
    "\n",
    "Throughout this project, you will be using other datasets to assist with analysis and predictions. Traditionally, to join dataframes we need to join on a specific column with shared values. However, when it comes to locations, exact latitudes and longitudes are hard to come by since it is a continuous space. First, lets look at such a dataset that we may want to merge on with `epa_data_CA_merged`. \n",
    "\n",
    "In the below cell, we have loaded in the `traffic_data` dataset, which contains traffic data for various locations in California. Your task is to clean this table so that it includes only the following columns (you may have to rename some): `District`, `Route`, `County`, `Descriptn`, `AADT`, `Latitude`, `Longitude`, where `AADT` is found by taking the sum of the back and ahead `AADT`s (you may run into some issues with cleaning the data in order to add these columns - `.str` functions may help with this). The metric AADT, annual average daily traffic, is calculated as the sum of the traffic north of the route (ahead AADT) and south of the route (back AADT). You also need to make sure to clean and remove any illegal values from the dataframe (hint: check `Latitude` and `Longitude`).\n",
    "\n",
    "*Hint:* `str` functions you will likely use: `.strip()`, `.replace()`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbd51a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_data = pd.read_csv(\"data/Traffic_Volumes_AADT.csv\")\n",
    "traffic_data_cleaned = ...\n",
    "\n",
    "\n",
    "traffic_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e1457",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e35cda",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2b - Merging on Traffic Data \n",
    "\n",
    "Traditionally, we could employ some sort of join where we join `epa_data_CA_merged` rows with the row in `traffic_data` that it is the \"closest\" to, as measured by euclidean distance. As you can imagine, this can be quite tedious so instead we will use a special type of join called a **spatial join**, which can be done using the package `geopandas`, which is imported as `gpd`. The documentation for `geopandas` is linked [here](https://geopandas.org/docs/reference/api/geopandas.sjoin_nearest.html). Please use this as a resource to do the following tasks: \n",
    "\n",
    " - turn `traffic_data_cleaned` and `epa_data_CA_merged` into a geopandas dataframe using the latitude and longitude.\n",
    " - Use a spatial join (which function is this in the documentation?) to match the correct traffic row information to each entry in `epa_data_CA_merged`. \n",
    "\n",
    "Your final dataframe should be assigned to `gpd_epa_traffic` with the following columns: `State Name`, `county Name`, `Month`, `Day`, `AQI`, `Category`, `Defining Site`, `Site Lat`, `Site Long`, `Traffic Lat`, `Traffic Long`, `Descriptn`, and `AADT`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eef79865",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd_epa_traffic = ...\n",
    "\n",
    "\n",
    "\n",
    "gpd_epa_traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551886e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc72f6c9",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "## Section 2: Guided EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b60cd6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3a: Initial AQI Analysis\n",
    "\n",
    "Assign a `pd.Series` object to `worst_median_aqis` that contains the states with the top 10 worst median AQIs throughout the year 2020, as measured by the average median AQIs across all counties for a single state. Your result should have index `state`, the column value should be labelled `Average Median AQI`, and it should be arranged in descending order.\n",
    "\n",
    "Now, assign the same thing to `worst_max_aqis`, except instead of aggregating the average median AQIs across all counties, aggregate the average **max AQIs** across all counties. Your result should have the same shape and labels as before, except the column value should be labelled `Average Max AQI`. \n",
    "\n",
    "Note: you may have to remove a few regions in your tables. Make sure every entry in your output is a **US State**.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61aac8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_median_aqis = ...\n",
    "worst_max_aqis = ...\n",
    "\n",
    "\n",
    "print(\"Worst Median AQI : \\n{}\\n\".format(worst_median_aqis))\n",
    "print(\"Worst Max AQI : \\n{}\".format(worst_max_aqis))\n",
    "\n",
    "np.round(list(worst_max_aqis), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f7328",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed7af0d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 3b: Worst AQI States\n",
    "\n",
    "What are the states that are in both of the top 10 lists? Why do you think most of these states are on both of the lists?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe8e40",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b9ef4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 4a: Missing AQI Data\n",
    "\n",
    "We want to see the accessibility of the AQI data across states. In the following cell, assign `days_with_AQI` to a series that contains the state as the index and the average number of days with AQI entries across all counties in that state as the value. Make sure to label the series as `Days with AQI` and sort in ascending order (smallest average number of days at the top). As before, make sure to remove the regions that are not **US States** from your series.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "200bab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_with_AQI = ...\n",
    "\n",
    "\n",
    "days_with_AQI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7982396",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eeaccc",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Question 4b: What are the missing dates?\n",
    "\n",
    "In the following cell, we create the series `ca_aqi_days` that outputs a series with each county in California mapped to the number of days that they have AQI data on. Notice that there exists a few counties without the full year of data, which is what you will be taking a closer look at in the following two parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9442b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_annual_data = epa_data.get('annual_county_aqi')[epa_data.get('annual_county_aqi')['State'] == 'California']\n",
    "ca_aqi_days = ca_annual_data['Days with AQI'].sort_values()\n",
    "ca_aqi_days.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d52bc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 4bi: Missing Days\n",
    "\n",
    "Assign `county_to_missing_dates` to a dictionary that maps each county with less than the full year of data to the dates that have missing AQI data. Make sure that your keys are just the county name (no whitespace around it or `, California` appended to it) and the values are of the format `yyyy-mm-dd`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4i\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c64da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_to_missing_dates = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2470372",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff49cc54",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 4bii: Missing Days\n",
    "\n",
    "Are there any key missing dates in common between the counties that have missing AQI data? What two counties have the most missing days and why do you think they do?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4bii\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c6c60a",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbc718f",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 5a: AQI over Time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeba668",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Assign `aqi_per_month` to a series of the average aqi per month across all US states and `aqi_per_month_CA` to a series of the average AQI per month across California.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a243c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_per_month = ...\n",
    "aqi_per_month_CA = ...\n",
    "\n",
    "\n",
    "print(\"AQI per Month: \\n{}\\n\".format(aqi_per_month))\n",
    "print(\"AQI per Month California : \\n{}\".format(aqi_per_month_CA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e76e1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738baa95",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 5b: AQI over Time Analysis \n",
    "\n",
    "Is there anything interesting that you notice in `aqi_per_month_CA`? If so, why do you think that is?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5b\n",
    "manual: True\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8fcea7",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e939efa5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 5c: Modeling AQI over Time\n",
    "\n",
    "Based on the AQI pattern in the year 2020, if we were to model AQI over the last 10 years, with the average AQI per year being the same, what sort of parametric function $f(x)$ would you use? Let us say that we see a linear increase in the average AQI per year over the last 10 years instead, then what parametric function $g(x)$ would you use?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5c\n",
    "manual: True\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e24030",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389dc921",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 6a: Create Heatmap Buckets\n",
    "\n",
    "Now we want to create a function called `bucket_data`, which takes in the following parameters: `table`, `resolution`. It outputs a pivot table with the latitude bucket (smallest latitude for that grid point) on the index and the longitude bucket (smallest longitude for that grid point) on the columns. The values in the pivot table should be the average AQI of the monitor sites inside that respective rectangle grid of latitudes and longitudes. The following should be the output of `bucket_data(epa_data_CA_merged, np.mean, 5)`:\n",
    "\n",
    "<img src=\"images/q6a.png\" width=\"600px\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b89123",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The `resolution` parameter describes the number of buckets that the latitudes and longitudes are divided into on the heatmap. As an example, let us say that the range of longitudes for site monitors are between \\[100, 110\\]; make sure that the start of the range is exactly the **minimum** of all longitude values of your site monitors and the end of the range is the exactly the **maximum** of all longitude values of your site monitors. Let us say that we have a resolution of 10. Then we have the buckets \n",
    "$$([100, 101], [101, 102], ..., [109, 110])$$\n",
    "\n",
    "The column and row labels of this dataframe should be labelled as the **start** of the bucket. In the case of the example above, the names of the buckets should be $ 100, 101, \\dots 109 $. Note that we are just looking at the longitude dimension in this example, and you have to do do the same for the latitude dimension along the rows in order to build the pivot table.\n",
    "\n",
    "Finally, make sure the row and column labels of your pivot table are **exactly** the same as the example given above. \n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "points: 6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7c0eb71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_data(table, aggfunc, resolution):\n",
    "    ...\n",
    "\n",
    "\n",
    "bucket_data(epa_data_CA_merged, np.mean, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b097507",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ec7023",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "### Question 6b: Visualize Heatmap\n",
    "\n",
    "Assign `heatmap_data` to a heatmap bucket pivot table aggregated by median with resolution 30 for California AQI for the month of september. The code in the following cell will plot this heatmap for you. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80dddafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = ...\n",
    "\n",
    "\n",
    "#create visualization\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.heatmap(heatmap_data, vmin=0, vmax=230, cmap = sns.cm.rocket_r)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c7478",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1c343",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 6c: Analyze Heatmap\n",
    "\n",
    "Look up where the dark regions correspond to. Does this heatmap make sense?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6c\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1338999e",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e18aa",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "---\n",
    "## Part 3: Open-Ended EDA\n",
    "\n",
    "Not that we have explored the data both spatially and temporally, we want to be able to look at what other indicators there are for air quality in California. Through the previous few questions we have discussed that wilfire data as well as temperature may be good indicators, but we can explitly look at correlations via the temperature to verify our hypothesis. Like temperature, there are other columns of data such as particulate matter, chemical concentrations, wind data, etc. Your open-ended EDA will be useful for filling in missing points in the heatmap that you created in question 4b. \n",
    "\n",
    "Your goal in this question is to find relationships between AQI and other features in the current datasets, across time and space. Your exploration can include, but is not limited to: \n",
    "- Looking at correlations between AQI and various columns of interest in `epa_data_CA`.\n",
    "    - This will require some merging, which you can look at question 1 for reference. \n",
    "- Performing clustering and/or other unsupervised learning methods such as PCA to discover clusters or useful (combinations of) features in the data.\n",
    "- Merging and exploring other external datasets that you may think are useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af361520",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 7a - Code and Analysis\n",
    "\n",
    "Please complete all of your analysis in the **single cell** below based on the prompt above.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7a\n",
    "manual: True\n",
    "points: 10\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d584c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_data.get('annual_county_aqi').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40a68bb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 7b - Visualization\n",
    "\n",
    "Please create **two** visualizations to summarize your analysis above. The only restrictions are that these visualizations **cannot** simply be scatterplots between two features in the dataset(s) and **cannot** be of the same type (dont make two bar graphs, for example). \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7b\n",
    "manual: True\n",
    "points: 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f94c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e4060",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 7c - Summary\n",
    "\n",
    "In a paragraph, summarize the your findings and visualizations and explain how they will be useful for predicting AQI. Make sure that your answer is thoughtful and detailed in that it describes what you did and how you reached your conclusion. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7c\n",
    "manual: True\n",
    "points: 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540a0fb7",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bed937a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "---\n",
    "## Part 4: Guided Modeling\n",
    "\n",
    "For this part, we will be looking at some open-ended modeling approaches to answering the question of predicting AQI given a location and a date. \n",
    "\n",
    "### Question 8 - Interpolation\n",
    "\n",
    "For this part, we will be using a simple interpolation to find the missing grid values for AQI on the heatmap visualization that you produced in part 1. Simple linear interpolation just takes the locations' values and averages them to produce an estimate of the current location. Though this is not as predictive (we are not predicting based on features about the location itself), it will give you a sense of the task at hand for the remainder of the project. \n",
    "\n",
    "As a reminder, the heatmap produced after running the cell below is the one you produced for question 6b when creating a visualization for the AQI in California for the month of september. It produces white spaces where there exist `NaN` values in the pivot table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61fe3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_sep = epa_data_CA_merged[epa_data_CA_merged['Month'] == 9]\n",
    "heatmap_data = bucket_data(table_sep, np.median, 25)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.heatmap(heatmap_data, vmin=0, vmax=230, cmap = sns.cm.rocket_r)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c3a87",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "### Question 8a - Simple Linear Interpolation\n",
    "As previously mentioned, interpolation is a technique that is used to predict labels in a dataset by forming a model out of the data that is already labelled. In this case, we have a pivot table that we use to create a heatmap, but there contains many `NaN` values that we want to fill in. \n",
    "\n",
    "- Create the function `fill_bucket` that takes in the following parameters:\n",
    "    - `pivot_table`: the pivot table that we are providing. \n",
    "    - `lat_bucket`: the bucket number that the latitude is in, indexed by zero. ex. if there are 25 buckets, they are numbered $ 0, 2, \\dots 24 $, from lowest to highest value latitudes. \n",
    "    - `lon_bucket`: the bucket number that the longitude is in, indexed by zero. ex. if there are 25 buckets, they are numbered $ 0, 2, \\dots 24 $. from lowest to highest value longitudes.\n",
    "    \n",
    "- In the pivot table, every value has cells above (A cells), cells below (B cells), cells to the left (L cells), and cells to the right (R cells). We will say that a direction (R for example) is valid if and only if there exists a cell **anywhere** to its right that is not `NaN`. The closest such cell will be called the \"closest R cell\". The same goes for the rest of the directions. For the cases below, assuming that our current cell is called cell K. \n",
    "    - If cell K is not `NaN`, then simply return the AQI at that given cell.\n",
    "    - **Only** if there are **at least** three valid directional cells (ex. has A, B, and L valid but not R valid), we will call K *interpolable*. If K is *interpolable*, then interpolate K by assigning it an AQI value equal to the average of the closest cell AQIs in each of the valid directions. \n",
    "    - If K is *not interpolable*, then do not do anything and simply return `NaN`.\n",
    "- The return value of `fill_bucket` should be the the value assigned to K. **DO NOT** mutate the cell K in the pivot table yet.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8a\n",
    "points: 6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "dd43b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_bucket(pivot_table, lat_bucket, lon_bucket):\n",
    "    ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eab44a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f24e9a7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "### Question 8b - Create Filled Heatmap\n",
    "\n",
    "Now that you have created the `fill_bucket` function, we want to actually use it to fill in the values in `heatmap_data`. Complete the function `fill_all` that takes in the pivot table and fills in all the values and produces a pivot table with the updated values. **DO NOT** mutate the original pivot table. Instead, produce a new pivot table that that contains the filled values. \n",
    "\n",
    "One point to note is that when we update a cell here, we do not use any surrounding *interpolated* cells to do our interpolation on any given cell. As a result, we will always use the **original** pivot table to find surrounding cells and interpolate.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8b\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "30dc5001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_all(pivot_table):\n",
    "    ...\n",
    "\n",
    "\n",
    "filled_heatmap_data = fill_all(heatmap_data)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.heatmap(filled_heatmap_data, vmin=0, vmax=230, cmap = sns.cm.rocket_r)\n",
    "ax.invert_yaxis()\n",
    "plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c73af",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b7e54",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 8c - Other Interpolation Ideas\n",
    "\n",
    "Instead of just interpolating in a simple fashion as we did above, suggest one other way to interpolate (that actually works so do not just say \"put the average of all cells in every `NaN` cell). For example, you can take into account of the distance of the surrounding cells, the number of cells you use, and more. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8c\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102cfb47",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256edc81",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 9 - Choosing your Loss Function\n",
    "\n",
    "Let us say that you are trying to define a loss function $L(x_{i}, y_{i})$ to use for model, where $x_{i}$ is the input and the $y_{i}$ is a qualitative variable that that model outputs, consisting of the following five groups: good, moderate, unhealthy for sensitive groups, unhealthy, very unhealthy, or hazardous. How would you design your loss function to evaluate your model?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q9\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e863ad",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea97f3e",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "</br></br>\n",
    "\n",
    "### Question 10: Creating your own Model!\n",
    "\n",
    "Now that you have an idea of how to interpolate values, we will be using something more predictive. In this part, your final goal is to be creating a model and function that uses **at least four** features, with at least one of those four features being from an external dataset that you bring in and process yourself. Here are some rules on the model that you should follow: \n",
    "\n",
    "- Using your open-ended EDA analysis, use at least three features in the dataset provided to come up with some sort of predictive model for the AQI for remaining locations not predicted in the heatmap. You are **NOT** allowed to use any more than **one** of the particulate matter features for this model i.e. ozone or CO2 concentrations for example. \n",
    "    - The reason behind this is that AQI is directly based on these values, so there will be in some sense a near 100\\% correlation between AQI and these features under some transformations. \n",
    "- Use at least one feature that comes from an external dataset of choice. Some examples are geographical region (categorical), elevation (quantitative), or wilfire data. \n",
    "    - Reference question 2c of this project to see how to merge external data with the current EPA data.\n",
    "- Your model should, at the end, predict one of the following broad categories for the AQI: good, moderate, unhealthy for sensitive groups, unhealthy, very unhealthy, or hazardous. Note that this specification is different from `fill_bucket` in the sense that instead of returning a value, you will be returning a string for a category.\n",
    "    - As a result, you can either directly predict the category, or the AQI (ex. through regression) and then convert to the category. Category ranges for AQI can be found online.\n",
    "- The final model should be validated with some data that you hold out. You decide how to do this but there should be some model validation accuracy reported. You should be using the loss function that you designed in question 3 in order to do this.\n",
    "\n",
    "---\n",
    "\n",
    "#### Deliverables\n",
    "<br/>\n",
    "\n",
    "**`features`**: This should be a `pd.DataFrame` object that represents the design matrix that will be fed in as input to your model. Each row represents a data point and each column represents a feature. Essentially your $X$ matrix. \n",
    "\n",
    "**`targets`**: This should be a numpy array that where each value corresponds to the AQI value or AQI category for each of the data points in `features`. Essentially your $y$ vector. \n",
    "\n",
    "**`build_model`**: This function should have two parameters: `features` that will be used as input into your model as a `pd.DataFrame` object, and `targets` should be a numpy array of AQI values OR AQI categories. It should return a *function* or *object* that represents your model.\n",
    "\n",
    "**`predict`**: This function should have two parameters: `model`, the model that you build from the previous function `build_model`, and `features` that represent the design matrix for the test values that we want to predict. It should return the **AQI category** (not a value) that the model predicts for these inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc24c2fc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 10a: Choose Features and Model\n",
    "\n",
    "First, decide on the features that you will be using for your model. How predictive do you think each of the features that you chose will be of the AQI category? Then, how will you choose to make your model (multiple regression, decision trees, etc.)?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q10a\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8c83ba",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c84a3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Question 10b: Build Features\n",
    "\n",
    "Create the `build_features` function as described at the beginning of this part. You should also do any cleaning or merging of internal or external datasets in this part. Make sure to read the specifications of the function very carefully. The autograder will provide some sanity checks on your output.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q10b\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3c9390bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ...\n",
    "targets = ...\n",
    "\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df3e40",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q10b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e15c8d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "### Question 10c: Build Your Model!\n",
    "\n",
    "Create the `build_model` function as described at the beginning of this part. Make sure to read the specifications of the function very carefully. The autograder will provide some sanity checks on your output.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q10c\n",
    "points: 8\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0436e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(features, targets):\n",
    "    ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f4165",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q10c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ca710",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "### Question 10d: Predict Points\n",
    "\n",
    "Create the `predict` function as described at the beginning of this part. Make sure to read the specifications of the function very carefully. The autograder will provide some sanity checks on your output.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q10d\n",
    "points: 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1505232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"good\", \"moderate\", \"unhealthy sensitive groups\", \"unhealthy\", \"very unhealthy\", \"hazardous\"]\n",
    "\n",
    "def predict(model, dates, lats, lons):\n",
    "    ...\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f75bd7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q10d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95796ead",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/>\n",
    "\n",
    "### Question 10e: Model Validation and Performance\n",
    "\n",
    "Now that you have finished making your model, we want to see how well it performs on our data. In this question, use the following cell to split your data into training and validation sets. You should partition 70\\% of your data to be used as your training set, and the remaining to be used as your validation set. \n",
    "\n",
    "Assign `binary_error` to be the **fraction of inputs on your validation set that the your `predict` function classifies incorrectly.** Note that this is a binary loss in some sense as it assigns a loss of 1 to those points predicted incorrectly, and a loss of 0 to those points predicted correctly.\n",
    "\n",
    "Assign `cv_error` to be the the error on the validation set produced by the loss function $ L $ that you designed in question 3.\n",
    "\n",
    "*Hint*: you can use `train_test_split` from `sklearn`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q10e\n",
    "points: 8\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9b2a0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_error = ...\n",
    "cv_error = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db0aa0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q10e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b7e39",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "## Part 5: Open-Ended Modeling\n",
    "\n",
    "Now that you have had some experience with creating the a model from scratch using the existing data, you are now ready to explore other questions, such as the ones in your design document. In this section, you will use the tools that we developed in the previous parts to answer the hypothesis of your choice! Note that breaking your model-building and analysis process into modularized functions as you did above will make your code more interpretable and less error-prone. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c6038",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 11a\n",
    "\n",
    "Train a baseline model of your choice using any supervised learning approach we have studied to answer your hypothesis and predict something related to AQI; you are not limited to a linear model. However, you may use a maximum of **three features** for this part. After training, evaluate it on some validation data that you hold out yourself. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q11a\n",
    "points: 5\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "62b08e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2558166",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 11b\n",
    "\n",
    "Explain and summarize the model that you used. In your summary, make sure to include the model description, the inputs, the outputs, as well as the cross-validation error. Additionally, talk a little bit about what you would change to your baseline model to improve it. The expected length of your summary should be 8-12 sentences. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q11b\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf47b9",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4b2852",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 11c\n",
    "\n",
    "Improve your model from part 11a based on the improvements that you suggested in part 11b. This could be the addition of more features, performing additional transformations on your features, increasing/decreasing the complexity of the model itself, or really anything else. You have no limitation on the number of features you can use, but you are required to use at least **one external dataset** that you process and merge in yourself. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q11c\n",
    "points: 8\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "60a5bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62956358",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 11d\n",
    "\n",
    "Compare and contrast your baseline model and (hopefully) improved model. Make sure to compare their validation errors. Were you able to successfully answer your research question and evaluate your hypothesis? Summarize in a few sentences the conclusions that you can draw from your model and predictions. The expected length of your response should be 8-10 sentences. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q11d\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c541f7ef",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8758917",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4521edc4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9946713b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d5a5c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d88d47",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
