{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eedd1c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Traffic.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0c57c",
   "metadata": {},
   "source": [
    "# Final Project: Traffic\n",
    "## Due Date: Monday, December 13th, 11:59 PM\n",
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with other groups about\n",
    "the project, we ask that you **write your solutions within your own groups**. If you do\n",
    "discuss the assignments with others outside of your group please **include their names** at the top\n",
    "of your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba9096",
   "metadata": {},
   "source": [
    "# Data 100 Final Project: Traffic in a post-lockdown world\n",
    "\n",
    "**Scenario:** You're a data scientist at Uber -- sitting in a war room on March 16, 2020, 1 day after California-wide COVID lockdown measures began and the day shelter-in-place measures are announced in the bay area. The entire data science department is on fire: All of your existing traffic models have regressed *significantly*. Given the sudden change in traffic patterns (i.e., no traffic at all), the company's traffic estimates are wildly incorrect. This is a top priority for the company. Since traffic estimates are used directly for pricing strategies, this is actively costing the company millions every hour. You are tasked with fixing these models.\n",
    "\n",
    "**Takeaways:** How do you \"fix\" models that have learned biases from pre-lockdown traffic? How do you train new ones, with just 24 hours of data? What sorts of data do you examine, to better understand the situation? In the midst of company-wide panic, you'll need a strong inferential acumen to lead a robust data science response. In this project, we'll walk you through a simulated war room data science effort, culminating in some strategies to fix models online, which are experiencing large distributional shifts in data.\n",
    "\n",
    "For this project, we'll explore traffic data provided by the **Uber Movement** dataset, specifically around the start of COVID shutdowns in March 2020. Your project is structured around the following ideas:\n",
    "\n",
    "```\n",
    "1. Guided data cleaning: Clustering data spatially\n",
    "    a. Load Uber traffic speeds dataset\n",
    "    b. Map traffic speeds to Google Plus Codes (spatially uniform)\n",
    "        i. Load node-to-gps-coordinates data\n",
    "        ii. Map traffic speed to GPS coordinates\n",
    "        iii. Convert GPS coordinates to plus code regions\n",
    "        iv. Sanity check number of plus code regions in San Francisco\n",
    "        v. Plot a histogram of the standard deviation in speed, per plus code region.\n",
    "    c. Map traffic speeds to census tracts (spatially non-uniform)\n",
    "        i. Download census tracts geojson\n",
    "        ii. Map traffic speed to census tracts\n",
    "        iii. Sanity check number of census tracts in San Francisco with data.\n",
    "        iv. Plot a histogram of the standard deviation in speed, per census tract.\n",
    "    d. What defines a \"good\" or \"bad\" spatial clustering?\n",
    "2. Guided EDA: Understanding COVID lockdown impact on traffic\n",
    "    a. How did lockdown affect average traffic speeds?\n",
    "        i. Sort census tracts by average speed, pre-lockdown.\n",
    "        ii. Sort census tracts by average speed, post-lockdown.\n",
    "        iii. Sort census tracts by change in average speed, from pre to post lockdown.\n",
    "        iv. Quantify the impact of lockdown on average speeds.\n",
    "        v. Quantify the impact of pre-lockdown average speed on change in speed.\n",
    "    b. What traffic areas were impacted by lockdown?\n",
    "        i. Visualize heatmap of average traffic speed per census tract, pre-lockdown.\n",
    "        ii. Visualize change in average daily speeds pre vs. post lockdown.\n",
    "        iii. Quantify the impact of lockdown on daily speeds, spatially.\n",
    "3. Open-Ended EDA: Understanding lockdown impact on traffic times\n",
    "    a. Download Uber Movement (Travel Times) dataset\n",
    "4. Guided Modeling: Predict traffic speed post-lockdown\n",
    "    a. Predict daily traffic speed on pre-lockdown data\n",
    "        i. Assemble dataset to predict daily traffic speed.\n",
    "        ii. Train and evaluate linear model on pre-lockdown data.\n",
    "    b. Understand failures on post-lockdown data\n",
    "        i. Evaluate on post-lockdown data\n",
    "        ii. Report model performance temporally\n",
    "    c. \"Fix\" model on post-lockdown data\n",
    "        i. Learn delta off of a moving bias\n",
    "        ii. Does it \"solve itself\"? Does the pre-lockdown model predict, after the change point?\n",
    "        iii. Naively retrain model with post-lockdown data\n",
    "        iv. What if you just ignore the change point?\n",
    "5. Open-Ended Modeling: Predicting travel times post-lockdown\n",
    "```\n",
    "\n",
    "Concepts tested: regex, pivot, join, grouping, inferential thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac22504",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import contextily as cx\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from typing import Callable\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from zipfile import ZipFile\n",
    "zf = ZipFile('data.zip', 'r')\n",
    "zf.extractall('.')\n",
    "\n",
    "# more readable exceptions\n",
    "%pip install --quiet iwut\n",
    "%load_ext iwut\n",
    "%wut on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1170aa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 1 - Guided Data Cleaning: Partitioning Data Spatially\n",
    "\n",
    "Our hope is answer: How do we group information spatially? We'll specifically look at 2 ways of partitioning data spatially, to understand the impact of spatial partitioning strategies on our analyses:\n",
    "\n",
    "1. Dividing the world uniformly into slices, like Google's plus codes.\n",
    "2. Dividing the world according to population, using census tracts.\n",
    "\n",
    "In this step, we'll load the following datasets that we'll need for this project:\n",
    "\n",
    "- Daily travel times from Uber Movement data in March 2020 from San Francisco, by census tract\n",
    "- Daily traffic speeds from Uber Movement data in Q1 2020 from San Francisco, between OSM nodes\n",
    "- Census tracts dividing San Francisco by GPS coordinates\n",
    "- Mapping from OSM nodes to GPS coordinates\n",
    "\n",
    "There are several terms and concepts to get familiar with upfront:\n",
    "\n",
    "- **Open Street Maps (OSM)** provides nodes (points in space, [wiki](https://wiki.openstreetmap.org/wiki/Node)) and ways (segments between nodes [wiki](https://wiki.openstreetmap.org/wiki/Way)). These IDs are used in the Uber Movement dataset to identify streets in the traffic speeds dataset.\n",
    "- **Census Tracts** provided by the county of San Francisco geographically divides space according to the US 2010 Census. This is used in the Uber Movement dataset to identify regions of differing travel times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972f63f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1.a. Load Uber traffic speeds dataset\n",
    "\n",
    "The dataset is located at `data/movement-speeds-daily-san-francisco-2020-3.csv`. **Load this dataset into a dataframe.**\n",
    "\n",
    "*The original dataset from Uber was provided hourly and took up 2.1 GB on disk, which means it couldn't fit into your 1GB of RAM. You can find the dataset preparation script at `data/PrepareTrafficDataset.ipynb` which aggregated within each day, reducing the dataset to just 55MB on disk.*\n",
    "\n",
    "*This was originally going to be question in this project, but it takes 22 minutes to run. Better yet, if you mess up, your kernel dies and you start over. We deemed it too frustrating and preprocessed the dataset to spare you the pain... but just know that this is a real-world issue!*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa7b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Uber Movement (Movement Speeds) dataset into dataframe\n",
    "speeds_to_nodes = ...\n",
    "\n",
    "speeds_to_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f96bb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ce62e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 1.b. Map traffic speed to Google Plus Codes\n",
    "\n",
    "Google Plus Codes divide up the world uniformly into rectangular slices ([link](https://maps.google.com/pluscodes/)). Let's use this to segment traffic speeds spatially. Take a moment to answer: **Is this spatial structure effective for summarizing traffic speed?** Before completing this section, substantiate your answer with examples of your expectations (e.g., we expect A to be separated from B). After completing this section, substantiate your answer with observations you've made.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdfc8c4",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d25e2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 1.b.i. Load Node-to-GPS-Coordinate Data\n",
    "\n",
    "In this substep, we'll load a mapping from OSM nodes to GPS coordinates. The dataset is provided in a gzip'ed XML file from OpenStreetMaps (OSM). The mapping from OSM nodes to GPS coordinates was downloaded from https://download.bbbike.org/osm/bbbike/SanFrancisco/SanFrancisco.osm.gz. We've downloaded this for you, to avoid any issues with OSM updates.\n",
    "\n",
    "**If** you try to load the provided `.osm` (an `.xml` in disguise) using Python's built-in XML utilities **(by uncommenting the last 2 lines in the below cell)**, you will hit an out-of-memory error, as your kernel is forced to restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b734bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [OSM] - Read the OSM XML and extract mapping from node ID to GPS coordinates\n",
    "PATH_OSM = os.path.expanduser('data/SanFrancisco.osm')\n",
    "\n",
    "# Runs out of memory! File itself is 430 MB, even when filtering out\n",
    "# irrelevant rows, and remaining 3M rows are too expensive to parse,\n",
    "# resulting in OOM\n",
    "\n",
    "# import xml.etree.ElementTree as ET\n",
    "# _tree = ET.parse(PATH_OSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de7d9e",
   "metadata": {},
   "source": [
    "Your above code hits a memory error, so instead, we will use our handy-dandy tool--regex--from earlier in the semester to load just the parts of the file that we need. **Given the XML snippet below, write a regex pattern to extract OSM node ID, latitude, and longitude.** (The first capture group should be node ID. The second should be latitude, and the third should be longitude.) A snippet of the XML is included below ([screenshot](https://extract.bbbike.org/extract-screenshots.html)):\n",
    "\n",
    "```\n",
    "<?xml version='1.0' encoding='UTF-8'?>\n",
    "<osm version=\"0.6\" generator=\"osmconvert 0.8.3\">\n",
    "    <bounds minlat=\"42.4543\" minlon=\"-2.4761999\" maxlat=\"42.4...\"/>\n",
    "    <node id=\"26861066\" lat=\"42.471111\" lon=\"-2.454722\" version=\"...\"/>\n",
    "        <tag k=\"name\" v=\"Camping La Playa\"/>\n",
    "        <tag k=\"tourism\" v=\"camp_site\"/>\n",
    "        <tag k=\"operator\" v=\"private\"/>\n",
    "        ...\n",
    "    </node>\n",
    "    <node id=\"34793287\" lat=\"42.4713587\" lon=\"-2.4510783\" version=\"...\"/>\n",
    "        <tag k=\"created_by\" v=\"JOSM\"/>\n",
    "    </node>\n",
    "    <node id=\"34793294\" lat=\"42.4610836\" lon=\"-2.4303622\" version=\"...\"/>\n",
    "    <node id=\"34793297\" lat=\"42.4548363\" lon=\"-2.4287657\" version=\"...\"/>\n",
    "    ...\n",
    "</osm>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b82c675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [OSM] - Read the OSM XML using a regex operation instead.\n",
    "def read_node_lat_lon(path: str, pattern: str, line_condition: Callable):\n",
    "    \"\"\"\n",
    "    Read the provided path line at a line. If the provided regex pattern\n",
    "    has a match, return the grouped matches as items in a generator.\n",
    "    \n",
    "    :param path: Path to read data from\n",
    "    :param pattern: Regex pattern to test against each line\n",
    "    :param line_condition: function that returns if we should check regex\n",
    "        against current line\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            result = re.search(pattern, line)\n",
    "            if result is not None and line_condition(result):\n",
    "                yield int(result.group(1)), float(result.group(2)), float(result.group(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bbae0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids = set(speeds_to_nodes.osm_start_node_id) | set(speeds_to_nodes.osm_end_node_id)\n",
    "\n",
    "NODE_PATTERN = r\"...\"\n",
    "\n",
    "node_to_gps = pd.DataFrame(read_node_lat_lon(\n",
    "    PATH_OSM,\n",
    "    pattern=NODE_PATTERN,\n",
    "    line_condition=lambda result: int(result.group(1)) in node_ids\n",
    "), columns=['osm_node_id', 'Latitude', 'Longitude'])\n",
    "node_to_gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253fe3a7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1bi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d2e3dd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.b.ii. Map traffic speed to GPS coordinates.\n",
    "\n",
    "Traffic speeds are currently connected to OSM nodes. You will then use the mapping from OSM nodes to GPS coordinates, to map traffic speeds to GPS coordinates. **Link each traffic speed measurement to the GPS coordinate of its starting node.**\n",
    "\n",
    "**Note**: For simplicity, assume each segment is associated with the node it *starts* with. \n",
    "\n",
    "**Hint**: Not all nodes are included in the OSM node mapping. Make sure to ignore any nodes without valid GPS coordinates.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1bii\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dbc5f8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find mapping from traffic speeds to GPS coordinates\n",
    "speeds_to_gps = ...\n",
    "speeds_to_gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f931cc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1bii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd3be0e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.b.iii. Convert GPS coordinates to plus code regions.\n",
    "\n",
    "Plus code regions divide up the world into uniformly-sized rectangles, which we will assume is 0.012 degrees latitudiunally and longitudinally. **For each traffic speed row, compute the plus code region it belongs to**, based on its GPS coordinates.\n",
    "\n",
    "To do this, we suggest computing a latitudinal index `plus_latitude_idx` and a longitudinal index `plus_longitude_idx` for the plus code region each row belongs to. *Make sure these columns are integer-valued*.\n",
    "\n",
    "**Hint**: If you're running into nans, you did 1.b.ii. incorrectly!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1biii\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e3bb4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "... # do this however you like\n",
    "\n",
    "speeds_to_gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43568f79",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1biii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6eccf8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.b.iv. Sanity check number of plus code regions in San Francisco.\n",
    "\n",
    "**Compute the number of unique plus codes found in your dataset**. You're checking that the number isn't ridiculous, like 1, or 100,000 (SF is 231 sq mi, so 100k tracts would average 12 sq ft per tract).\n",
    "\n",
    "If you followed the suggestion above, this is the number of unique `(plus_latitude_idx, plus_longitude_idx)` pairs.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1biv\n",
    "points: 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fc353f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You're expecting 276 plus codes here. Don't just type \"276\" \n",
    "# below to pass the autograder. The goal is to sanity check your \n",
    "# dataframe!\n",
    "num_pluscode_regions = ...\n",
    "num_pluscode_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969c637",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1biv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d50542",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.b.v. How well do plus code regions summarize movement speeds?\n",
    "\n",
    "The following will give us an idea of how well the average represents traffic speed per plus code region. For these questions, we'll refer to a \"plus code region\" as a \"cluster\":\n",
    "\n",
    "1. **Plot a histogram of the within-cluster standard deviation**.\n",
    "2. **Compute across-cluster average of within-cluster standard deviation**.\n",
    "3. **Compute across-cluster standard deviation of within-cluster average speeds**.\n",
    "4. **Is this average variance reasonable?** To assess what \"reasonable\" means, consider these questions and how to answer them: (1) Do plus codes capture meaningful subpopulations? (2) Do differences between subpopulations outweigh differences within a subpopulation? Use the statistics above to answer these questions, and compute any additional statistics you need. Additionally explain *why these questions are important to assessing the quality of a spatial clustering*.\n",
    "\n",
    "**Hint**: Run the autograder first to ensure your variance average and average variance are correct, before starting to draw conclusions.\n",
    "\n",
    "In the first cell, write your written answers. In the second cell, complete the code.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1bv1\n",
    "points: 2\n",
    "manual: True\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f344ee2",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45a362",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1bv2\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00d9ec83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speed_variance_by_pluscode = ... # compute traffic speed variance in each plus code region\n",
    "# plot a histogram\n",
    "average_variance_by_pluscode = ...\n",
    "variance_average_by_pluscode = ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b9177",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1bv3\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dddeeddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_variance_by_pluscode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf561a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1bv3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a6e79",
   "metadata": {},
   "source": [
    "## 1.c. Map traffic speed to census tract.\n",
    "\n",
    "Census tracts divide the space much less uniformly, subdividing regions that we were interested in into smaller zones. This suggests promise in providing informative spatial segments. Note that the daily traffic speeds are provided between OpenStreetMap (OSM) nodes, so we'll need to map nodes to census tracts somehow.\n",
    "\n",
    "Above, we've mapped traffic speeds to GPS coordinates. Below, we'll then link GPS coordinates to census tracts, to complete the mapping from traffic speeds to census tracts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02aca27",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.c.i. Download Census Tracts Geojson\n",
    "\n",
    "**Load the census tracts geojson.** Make sure to see the relevant [geopandas io documentation](https://geopandas.org/docs/user_guide/io.html) to see how to load a geojson.\n",
    "\n",
    "**Hint**: It should take you just one line to load.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1ci\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "905c8c7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH_TRACTS = os.path.expanduser('data/san_francisco_censustracts.json')\n",
    "tract_to_gps = ...\n",
    "tract_to_gps['MOVEMENT_ID'] = tract_to_gps['MOVEMENT_ID'].astype(int)\n",
    "tract_to_gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad51eba",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1ci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a801db2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.c.ii Map traffic speed to census tracts.\n",
    "\n",
    "You will need to *spatially join* the (1) mapping from traffic speed to GPS coordinates `speed_to_gps` and (2) the mapping from GPS coordinates to boundaries of census tracts `tract_to_gps` to group all traffic speeds by census tract. This \"spatial join\" is an advanced feature recently released (as of time of writing, in Oct 2021) in geopandas, which allows us to connect single points to their enclosing polygons. You will do this question in 3 parts:\n",
    "\n",
    "1. Convert the last dataframe `speeds_to_gps` into a geopandas dataframe `speeds_to_points`, where GPS coordinates are now geopandas points. See this tutorial: https://geopandas.org/gallery/create_geopandas_from_pandas.html#From-longitudes-and-latitudes\n",
    "2. Set the coordinate-system for the new geopandas dataframe to the \"world geodesic system\" [link](https://epsg.io/4326), or in other words, the coordinate system that GPS coordinates are reported in.\n",
    "3. Compute a spatial join between census tracts `tract_to_gps` and the geopandas traffic speeds `speeds_to_points`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1cii\n",
    "points: 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d2640f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_to_points = ...\n",
    "speeds_to_tract = ...\n",
    "\n",
    "speeds_to_tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8207f3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1cii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1746a1d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.c.iii. Aggregate movement speeds by census tract.\n",
    "\n",
    "- Create a new dataframe `speeds_by_tract` to group movement speeds by census tract. See the outputted dataframe from 1.c.i. to check how census tracts are identified.\n",
    "- Always double-check your numbers. **Report the number of census tracts** in your dataset.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1ciii\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b59dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_by_tract = ...\n",
    "num_census_tracts = ...\n",
    "...\n",
    "num_census_tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea4bd8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1ciii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d28ba4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.c.iv. How well do census tracts summarize movement speeds?\n",
    "\n",
    "The following will give us an idea of how well the average represents traffic speed per plus code region. For these questions, we'll refer to a \"census tract\" as a \"cluster\":\n",
    "\n",
    "1. **Plot a histogram of the within-cluster standard deviation**.\n",
    "2. **Compute across-cluster average of within-cluster standard deviation**.\n",
    "3. **Compute across-cluster standard deviation of within-cluster average speeds**.\n",
    "4. **Is this average variance reasonable?** To assess what \"reasonable\" means, consider these questions and how to answer them: (1) Do plus codes capture meaningful subpopulations? (2) Do differences between subpopulations outweigh differences within a subpopulation? Use these ideas to assess whether the average standard deviation is high or not.\n",
    "\n",
    "Note: We are using the speed metric of miles per hour here.\n",
    "\n",
    "Just like before, please written answers in the first cell and coding answers in the second cell.\n",
    "<!--5. Using the above, how would you **compare census tracts to plus codes, in terms of its effectiveness** as a spatial clustering mechanism for analyzing traffic speeds? Compare the statistics you've computed. What does it mean for one to be higher than the other?-->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1civ1\n",
    "points: 2\n",
    "manual: True\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e477c2",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7541ea2c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1civ2\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b0659c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_variance_by_tract = ...\n",
    "average_variance_by_tract = ...\n",
    "variance_average_by_tract = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4152b14",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1civ3\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d67893fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_variance_by_tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450781dc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1civ3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8719bc4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 1.d. What would be the ideal spatial clustering?\n",
    "\n",
    "This is an active research problem in many spatiotemporal modeling communities, and there is no single agreed-upon answer. Answer both of the following specifically knowing that you'll need to analyze traffic patterns according to this spatial clustering:\n",
    "\n",
    "1. **What is a good metric for a spatial structure?** How do we define good? Bad? What information do we expect a spatial structure to yield? Use the above parts and questions to help answer this.\n",
    "2. **What would you do to optimize your own metric for success in a spatial structure?**\n",
    "\n",
    "See related articles:\n",
    "\n",
    "- Uber's H3 [link](https://eng.uber.com/h3/), which divides the world into hexagons\n",
    "- Traffic Analysis Zones (TAZ) [link](https://en.wikipedia.org/wiki/Traffic_analysis_zone), which takes census data and additionally accounts for vehicles per household when dividing space\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3deac",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e227a7d7",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# Step 2 - Guided EDA: Understanding COVID Lockdown Impact on Traffic\n",
    "\n",
    "In this step, we'll examine the impact of COVID on traffic. In particular, we'll study 3 different questions:\n",
    "\n",
    "- How did lockdown affect traffic speed? What factors dictate how much lockdown affected traffic speed?\n",
    "- What areas of traffic were most impacted by lockdown?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6189c",
   "metadata": {},
   "source": [
    "## 2.a. How did lockdown affect traffic speed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d34be",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.a.i. Sort census tracts by average speed, pre-lockdown.\n",
    "\n",
    "Consider the pre-lockdown period to be March 1 - 13, before the first COVID-related restrictions (travel bans) were announced on March 14, 2020.\n",
    "\n",
    "1. **Report a DataFrame which includes the *names* of the 10 census tracts with the lowest average speed**, along with the average speed for each tract.\n",
    "2. **Report a DataFrame which includes the *names* of the 10 census tracts with the highest average speed**, along with the average speed for each tract.\n",
    "2. Do these names match your expectations for low speed or high speed traffic pre-lockdown?  What relationships do you notice? (What do the low-speed areas have in common? The high-speed areas?) For this specific question, answer qualitatively. No need to quantify. **Hint**: Look up some of the names on a map, to understand where they are.\n",
    "3. **Plot a histogram for all average speeds, pre-lockdown**.\n",
    "4. You will notice a long tail distribution of high speed traffic. What do you think this corresponds to in San Francisco? Write down your hypothesis.\n",
    "\n",
    "Hint: To start off, think about what joins may be useful to get the desired DataFrame.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2ai1\n",
    "points: 3\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd6ab04",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3492fb9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Answer the following question:\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2ai2\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d1543e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute the average speed per census tract (will use this later),\n",
    "# BEFORE the shelter-in-place was announced on March 14, 2020.\n",
    "# Autograder expects this to be a series\n",
    "averages_pre = ... \n",
    "# Autograder expects this to be a dataframe with name of census tract,\n",
    "# polygon for census tract, and average speed per census tract\n",
    "averages_pre_named = ...\n",
    "averages_pre_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b36e40",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2ai2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8a88f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "Report the lowest 10 census tracts with the lowest average speed\n",
    "Remember we want the NAME of each census tract too. For the autograder, please keep the name of the speed field, `speed_mph_mean`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2ai3\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17f0d961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bottom10_averages_pre = ...\n",
    "bottom10_averages_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31cb10",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2ai3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025b156",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Report the highest 10 census tracts with the highest average speed.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2ai4\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99de81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_averages_pre = ...\n",
    "top10_averages_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0890d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2ai4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236db138",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Plot the histogram\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2ai5\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "841c3925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fb7daae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.a.ii. Sort census tracts by average speed, post-lockdown.\n",
    "\n",
    "I suggest checking the top 10 and bottom 10 tracts by average speed, post-lockdown. Consider the post-lockdown period to be March 14 - 31, after the first COVID restrictions were established on March 14, 2020. It's a healthy sanity check. For this question, you should report:\n",
    "\n",
    "- **Plot a histogram for all average speeds, post-lockdown.**\n",
    "- **What are the major differences between this post-lockdown histogram relative to the pre-lockdown histogram above**? Anything surprising? What did you expect, and what did you find?\n",
    "\n",
    "Write the written answers in the cell below, and the coding answers in the cells after that.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2aii1\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21badcd1",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0267b65f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2aii2\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db352a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the average speed per census tract (will use this later),\n",
    "# AFTER (and including) the first COVID restrictions were put into effect.\n",
    "# Autograder expects this to be a series\n",
    "averages_post = ...\n",
    "# Autograder expects this to be a dataframe with name of census tract,\n",
    "# polygon for census tract, and average speed per census tract\n",
    "averages_post_named = ...\n",
    "averages_post_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae5025",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2aii2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d57ac7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Plot the histogram\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2aii3\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2ad73d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a8debfe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.a.iii. Sort census tracts by change in traffic speed from pre to post lockdown.\n",
    "\n",
    "For each segment, compute the difference between the pre-lockdown average speed (March 1 - 13) and the post-lockdown average speed (March 14 - 31). **Plot a histogram of all differences.** Sanity check that the below histogram matches your observations of the histograms above, on your own.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2aiii\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3edb8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The autograder expects differences to be a series object with index\n",
    "# MOVEMENT_ID.\n",
    "differences = ...\n",
    "# plot the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33affd69",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2aiii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f64a3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.a.iv. Quantify the impact of lockdown on average speeds.\n",
    "\n",
    "1. **Plot the average speed by day, across all segments**. Be careful not to plot the average of census tract averages instead. Recall the definition of segments from Q1.\n",
    "2. Is the change in speed smooth and gradually increasing? Or increasing sharply? Why? Use your real-world knowledge of announcements and measures during that time, in your explanation. You can use this list of bay area COVID-related dataes: https://abc7news.com/timeline-of-coronavirus-us-covid-19-bay-area-sf/6047519/\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2aiv1\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01e89ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autograder expects this to be a series object containing the\n",
    "# data for your line plot -- average speeds per day.\n",
    "speeds_daily = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69038b87",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Write your written answer in the cell below\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2aiv2\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c605563b",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad51b9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Ignore the empty cell below, just run the autograder to test the code above is correct.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2aiv3\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d2783df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d8b3f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2aiv3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ad0f5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.a.v. Quantify the impact of pre-lockdown average speed on change in speed.\n",
    "\n",
    "1. Compute the correlation between change in speed and the *pre*-lockdown average speeds. Do we expect a positive or negative correlation, given our analysis above?\n",
    "2. Compute the correlation between change in speed and the post-lockdown average speeds.\n",
    "3. **How does the correlation in Q1 compare with the correlation in Q2?** You should expect a significant change in correlation value. What insight does this provide about traffic?\n",
    "\n",
    "Written answers in the first cell, coding answerts in the following cell.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2av1\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf7933b",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad929d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2av2\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6ef2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pre_diff = ...\n",
    "corr_post_diff = ...\n",
    "corr_pre_diff, corr_post_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a894ce9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2av2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84bf0b",
   "metadata": {},
   "source": [
    "## 2.b. What traffic areas were impacted by lockdown?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c20b6a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.b.i. Visualize spatial heatmap of average traffic speed per census tract, pre-lockdown.\n",
    "\n",
    "Visualize a spatial heatmap of the grouped average daily speeds per census tract, which you computed in previous parts. Use the geopandas [chloropleth maps](https://geopandas.org/docs/user_guide/mapping.html#choropleth-maps). **Write your observations, using your visualization, noting down at least 2 areas or patterns of interest**. These may be a local extrema, or a region that is strangely all similar.\n",
    "\n",
    "**Hint**: Use [`to_crs`](https://geopandas.org/docs/reference/api/geopandas.GeoDataFrame.to_crs.html) and make sure the `epsg` is using the Pseudo-Mercator projection.\n",
    "\n",
    "**Hint**: You can use `contextily` to superimpose your chloropleth map on a real geographic map.\n",
    "\n",
    "**Hint** You can set a lower opacity for your chloropleth map, to see what's underneath, but be aware that if you plot with too low of an opacity, the map underneath will perturb your chloropleth and meddle with your conclusions.\n",
    "\n",
    "Written answers in the first cell, coding answers in the second cell.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2bi1\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd3d7a",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0351d12",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2bi2\n",
    "points: 4\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d680081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "600c6a78",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.b.ii. Visualize change in average daily speeds pre vs. post lockdown.\n",
    "\n",
    "Visualize a spatial heatmap of the census tract differences in average speeds, that we computed in a previous part. **Write your observations, using your visualization, noting down at least 2 areas or patterns of interest.** Some possible ideas for interesting notes: Which areas saw the most change in average speed? Which areas weren't affected? Why did some areas see *reduced* average speed?\n",
    "\n",
    "First cell is for the written answers, second cell is for the coding answers.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2bii1\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846910d",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e13db6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2bii2\n",
    "points: 4\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00384667",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3ac2e",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# Step 3 - Open-Ended EDA: Understanding lockdown impact on travel times\n",
    "\n",
    "Explore daily travel times from Hayes Valley to other destinations both before and throughout lockdown. Use the following questions as suggestions for what to explore, temporally and spatially:\n",
    "\n",
    "- How did lockdown affect travel times? Are there any meaningful factors that determined how travel time would be impacted? How was travel time affected over time?\n",
    "- Travel to which destinations were affected by lockdown? Are there surprisingly disproportionate amounts of impact in certain areas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbfca76",
   "metadata": {},
   "source": [
    "## 3.a. Load Datasets\n",
    "\n",
    "In this step, we will load two datasets:\n",
    "\n",
    "- Daily travel times from Hayes Valley to all other census tracts around San Francisco.\n",
    "- Daily travel times from 300 Hayes St to Golden Gate Park in San Francisco.\n",
    "\n",
    "For this specific set of data, we can ask several more questions; which questions you pursue are up to you, including any that you come up that are not on this list:\n",
    "\n",
    "- Which routes from Hayes Valley had similar impact on travel time? Did they share any factors in common? Traveling through the same place -- e.g., a freway? Traveling in similar areas e.g., residential areas?\n",
    "- Were clusters of routes impacted more severely than others over time? What determined the degree of impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fb8c734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH_TIMES = 'data/travel-times-daily-san-francisco-2020-3.csv'\n",
    "times_to_tract = pd.read_csv(PATH_TIMES)\n",
    "times_to_tract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324d4cc",
   "metadata": {},
   "source": [
    "# Step 4 - Guided Modeling: Predict traffic speed post-lockdown\n",
    "\n",
    "In this step, you'll train a model to predict traffic speed. In particular, you'll learn how to provide implicit supervision and correction to your model, when you know there's been a distribution shift in its data, leading to a large gap between train and test sets. You'll follow the following outline:\n",
    "\n",
    "- Build a model to predict daily traffic speed in San Francisco. Train and evaluate on *pre*-lockdown traffic speeds around the city.\n",
    "- Evaluate your model on post-lockdown traffic speeds. Where is your model most mistaken, and why?\n",
    "- Using this knowledge, how would you correct your model for a more accurate post-lockdown traffic predictor?\n",
    "\n",
    "\n",
    "The technical term for a phenomenon like the lockdown, which caused major distributional shifts in the data, is *change point*. A large body of work studies \"change point detection,\" but you'll be harder pressed to find a \"handling change point\" paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c0fb2",
   "metadata": {},
   "source": [
    "## 4.a. Predict daily traffic speed on pre-lockdown data\n",
    "\n",
    "For your model, you will predict daily traffic speed per census tract, given the previous $k=5$ daily traffic speeds for that census tract. In particular, say a matrix $A$ is $n \\times d$, where $n$ is the number of census tracts and $d$ is the number of days. We define the following inputs and labels:\n",
    "\n",
    "$$X_{(i,t)} = [A_{(i,t-5)}, A_{(i,t-4)}, A_{(i,t-3)}, A_{(i,t-2)}, A_{(i,t-1)}]$$\n",
    "$$y_{(i,t)} = [A_{(i,t)}]$$\n",
    "\n",
    "This just means that each sample $X_i$ includes speed averages from the previous 5 days for the $i$th census track."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f1a0de",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.a.i. Assemble dataset to predict daily traffic speed.\n",
    "\n",
    "Below, we've included skeletons for the helper functions we defined, to complete the problem. We highly recommend following this skeleton code, else we cannot guarantee staff support for debugging your work.\n",
    "\n",
    "\n",
    "**Hint**: What's wrong with collecting all samples, then randomly selecting some percentage to hold out? See the answer in the expandable below.\n",
    "\n",
    "<details>\n",
    "    <summary>[Click to expand] How to do train-validation split correctly, on time series</summary>\n",
    "    \n",
    "For a *time series* in particular, this random split would be cheating, because data within each day is highly correlated. Instead, you should hold out entire days from the dataset. In this case, you should hold out the last 2 days for your validation set.\n",
    "</details>\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4ai1\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a10ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_time_series(df: pd.DataFrame):\n",
    "    \"\"\"Convert your dataframe into a 'time series'.\n",
    "    \n",
    "    :param df: the original dataframe, mapping speeds to census tracts.\n",
    "        This dataframe should contain the `MOVEMENT_ID` (census tract id),\n",
    "        `day`, and average speed for that day `speed_mph_mean`\n",
    "    :return: a new dataframe that is formatted as n x d, where\n",
    "        n is the number of samples (census tracts) and d is the number of\n",
    "        dimensions (days). The values are the speeds.\n",
    "    \"\"\"\n",
    "time_series = dataframe_to_time_series(speeds_to_tract)\n",
    "time_series_pre = time_series.iloc[:, list(range(13))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c38a7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4ai1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e66942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_to_numpy(df: pd.DataFrame, T: int, n_val: int):\n",
    "    \"\"\"Convert your 'time series' into train-validate splits, in numpy\n",
    "    \n",
    "    You can assume your dataframe contains a `day` column where days\n",
    "    start from 1 and are consecutive.\n",
    "    \n",
    "    :param df: the dataframe formatted as n x d, where\n",
    "        n is the number of samples (census tracts) and d is the number of\n",
    "        dimensions (days). The values are the speeds.\n",
    "    :param T: number of days to include in each training sample\n",
    "    :param n_val: number of days to hold out for the validation set.\n",
    "        Say we have 5 total days in our dataset, T=2, n_val=2. This means\n",
    "        during training, we have samples that pull averages from days 1 and\n",
    "        2 to predict day 3: x=(1, 2), y=(3,) For validation, we have samples\n",
    "        like x=(2, 3), y=(4,) and x=(3, 4), y=(5,). This way, the model sees\n",
    "        data from days 4 and 5 only during validation.\n",
    "    :return: Set of 4 numpy arrays - X_train, y_train, X_val, y_val - where\n",
    "        X_* arrays are (n, T) and y_* arrays are (n,).\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "def remove_nans(X: np.array, y: np.array):\n",
    "    \"\"\"Remove all nans from the provided (X, y) pair.\n",
    "    \n",
    "    Note: A nan in X means that sample must be removed from *both X and y.\n",
    "        Likewise, a nan in y means that sample must be removed from *both\n",
    "        X and y.\n",
    "    \n",
    "    :param X: (n, T) array of model inputs\n",
    "    :param y: (n,) array of labels\n",
    "    :return: (X, y)\n",
    "    \"\"\"\n",
    "    if not len(X):\n",
    "        return X, y\n",
    "    ...\n",
    "answer = time_series_to_numpy(time_series, 10, 2)\n",
    "answer2 = remove_nans(answer[0], answer[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e28e6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4ai2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3fd28eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_to_dataset(time_series: pd.DataFrame, T: int, n_val: int):\n",
    "    \"\"\"Convert 'time series' dataframe to a numpy dataset.\n",
    "    \n",
    "    Uses utilites above `time_series_to_numpy` and `remove_nans`\n",
    "    \n",
    "    For description of arguments, see `time_series_to_numpy` docstring.\n",
    "    \"\"\"\n",
    "    ...\n",
    "X_train, y_train, X_val, y_val = time_series_to_dataset(time_series_pre, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ff589",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4ai3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54ebb7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f67b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3c1a0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9183455",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 4.a.ii. Train and evaluate linear model on pre-lockdown data.\n",
    "\n",
    "1. **Train a linear model that forecasts the next day's speed average** using your training dataset `X_train`, `y_train`. Specifically, predict $y_{(i,t)}$ from $X_{(i,t)}$, where\n",
    "- $y_{(i,t)}$ is the daily speed average for day $t$ and census tract $i$\n",
    "- $X_{(i,t)}$ is a vector of daily speed averages for days $t-5,t-4,t-3,t-2,t-1$ for census tract $i$\n",
    "2. **Evaluate your model** on your validation dataset `X_val`, `y_val`.\n",
    "3. **Make a scatter plot**, plotting predicted averages against ground truth averages. Note the perfect model would line up all points along the line $y=x$.\n",
    "\n",
    "Our model is quantitatively and qualitatively pretty accurate at this point, training and evaluating on pre-lockdown data.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4aii1\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5be823d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = ... # set to trained linear model\n",
    "score = ... # report r^2 score\n",
    "# create the scatter plot below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904db8f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4aii2\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e74913fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cc1e54",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4aii2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bfd2af",
   "metadata": {},
   "source": [
    "## 4.b. Understand failures on post-lockdown data\n",
    "\n",
    "Your dataset is distributed spatially and temporally. As a result, the most intuitive spaces to visualize your model error or performance along is both spatially and temporally. In this step, we focus on understanding *where* your model fails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43fe82",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.b.i. Evaluate on post-lockdown data\n",
    "\n",
    "1. Using your previously trained linear regression model `reg`, **evaluate on post-lockdown data**, meaning daily speed averages on March 14, 2020. Evaluate on all census tracts.\n",
    "2. **Make a scatter plot**, plotting predicted averages against ground truth averages. Note the perfect model would line up all points along the line $y=x$.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4bi1\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc8edff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_x_pre = ... # get 'time series' dataframe for days 8, 10, 11, 12, 13\n",
    "time_series_y_post = ... # get 'time series' dataframe for 14th\n",
    "score_pre_14th = ...\n",
    "score_pre_14th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46315050",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4bi1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c33b5a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_x_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d278129b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_series_y_post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91da701",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Make scatter plot below.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4bi2\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "385011bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15e05436",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 4.b.ii. Report model performance temporally\n",
    "\n",
    "1. **Make a line plot** showing performance of the original model throughout all of March 2020.\n",
    "2. **Report the lowest point on the line plot**, reflecting the lowest model performance.\n",
    "2. **Why is model performance the worst on the 17th?** Why does it begin to worsen on march 15th? And continue to worsen? Use what you know about covid measures on those dates. You may find this webpage useful: https://abc7news.com/timeline-of-coronavirus-us-covid-19-bay-area-sf/6047519/\n",
    "3. **Is the dip in performance on the 9th foreshadowed** by any of our EDA?\n",
    "4. **How does the model miraculously recover on its own?**\n",
    "5. **Make a scatter plot**, plotting predicted averages against ground truth averages *for model predictions on March 17th*. Note the perfect model would line up all points along the line $y=x$. When compared against previous plots of this nature, this plot looks substantially worse, with points straying far from $y=x$.\n",
    "\n",
    "**Note:** Answer questions 2-5 in the Markdown cell below. Q1 and Q6 are answered in the two code cells below.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4bii1\n",
    "points: 3\n",
    "manual: True\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae80544",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2cda7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Generate line plot.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4bii2\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e19a9db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0fd8a4c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Generate a scatter plot.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4bii3\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2cd380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad11a5",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## 4.c. \"Fix\" model on post-lockdown data\n",
    "\n",
    "Per this survey https://pure.tue.nl/ws/files/3488790/740215.pdf, there are 4 categories of fixes for change points:\n",
    "- Forgetting mechanisms\n",
    "- Explicit change detection\n",
    "- Ensemble techniques\n",
    "- Context-aware approaches\n",
    "\n",
    "In this part, we'll combine insights in model errors with previous EDA insights to produce a fix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219adccd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 4.c.i. Learn delta off of a moving bias\n",
    "\n",
    "According to our previous work in EDA, the average speed shoots upwards sharply. As a result, our trick to learn delta the around the average and to naively assume that the average of day $t$ is the average for day $t+1$. We will do this in 4 steps:\n",
    "\n",
    "1. **Create a dataset for your delta model**.\n",
    "2. **Train your delta model** on pre-lockdown data.\n",
    "3. **Evaluate your model on pre-lockdown data**, to ensure that the model has learned to a satisfactory degree, in the nominal case. Remember the naive model achieved 0.97 r^2 on pre-lockdown data.\n",
    "4. **Evaluate your model on the 17th**, to compare against the naive model also evaluated on that day. Notice that your r^2 score has improved by 10%+. Why is your delta model so effective for the 17th?\n",
    "5. **Evaluate your model on the 14th**, to compare against the naive model also evaluated on that day. Notice that your r^2 score is now complete garbage. Why is your delta so ineffective for the 14th?\n",
    "\n",
    "**Hint**: As you build your datasets, always check to make sure you're using the right days! It's easy to have a one-off error that throws off your results.\n",
    "\n",
    "Write your written questions in the next cell, then write the code in the following cells.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4ci1\n",
    "points: 2\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dafac4",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d3d68",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4ci2\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83c0171d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_series_delta = ... # subtract daily average from pre-lockdown 'time series' dataframe `time_series_pre`\n",
    "time_series_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d5cf3b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4ci2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eda7cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_delta_train, y_delta_train, X_delta_val, y_delta_val = ..., ..., ..., ...\n",
    "...\n",
    "res_4ci3 = reg_delta.score(X_delta_val, y_delta_val) # learning delta as easy as learning original dataset!\n",
    "res_4ci3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b32414",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4ci3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d00733a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_4ci4 = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e617a2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4ci4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "046257ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_4ci5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00819d08",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4ci5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cce1ba",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.c.ii. Does it \"solve itself\"? Does the pre-lockdown model predict, after the change point?\n",
    "\n",
    "Had we ignored the problem, would we have been okay? The temporal plot above showing performance over time suggests a partial recovery. **Evaluate the original, naive model on all post-lockdown data** to see. If your final r^2 score does not match the autograder's:\n",
    "- Double check you have selected daily average speeds for the right days, by printing your dataframe.\n",
    "- Double check you're using the right model (a brand new trained model)\n",
    "- Check you're using `T=5, n_val=2`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4cii\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f8f33751",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_og_post = ...\n",
    "...\n",
    "score_og_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17be53",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4cii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64c781",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.c.iii. Naively retrain model with post-lockdown data\n",
    "\n",
    "Can we use the same tactics--that we used to train the original model on pre-lockdown data--to train on the post-lockdown data? **Retrain a linear model and evaluate on post-lockdown data only**. You should construct a new dataset using `time_series_to_dataset` using only time series from March 14 to March 31. If your final r^2 score does not match the autograder's:\n",
    "- Double check you have selected daily average speeds for the right days, by printing your dataframe.\n",
    "- Double check you're using the right model (a brand new trained model)\n",
    "- Check you're using `T=5, n_val=2`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4ciii\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "be00ebaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_post = ...\n",
    "...\n",
    "score_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb292c1d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4ciii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17325151",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 4.c.iv. What if you just ignore the change point?\n",
    "\n",
    "Turns out, this is no good. Even acknowledging the change point and training *either* before *or* after is better. Being ignorant and training on *both* is the worst option, producing a lower r^2.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4civ\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "42833f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_4civ = ...\n",
    "res_4civ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c012320",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4civ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc358d",
   "metadata": {},
   "source": [
    "# Step 5 - Open-Ended Modeling: Predicting travel time post-lockdown\n",
    "\n",
    "*This* is the real deal and ultimately what Uber cares about. Traffic speeds is a proxy task, but the bottom line and moneymaking machine relies on this travel time estimation. Focus on designing experiments instead of focusing on experimental, quantitative results. Your experiments are successful if they inform a decision, even despite a lower-performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a75132",
   "metadata": {},
   "source": [
    "## Question 5a\n",
    "\n",
    "Train a baseline model of your choice using any supervised learning approach we have studied; you are not limited to a linear model.\n",
    "\n",
    "\n",
    "**Example**\n",
    "\n",
    "Given the data for this question, you could build a model to predict travel time from Cheesecake Factory to UC Berkeley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "130df711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71c3fdb3",
   "metadata": {},
   "source": [
    "## Question 5b\n",
    "\n",
    "Improve on your baseline model. Specify the model you designed and its input features. Justify why you chose these features and their relevance to your model's predictions.\n",
    "\n",
    "**Example**\n",
    "\n",
    "Here are potential questions to consider for this part: How does the other variant of your travel times dataset, aggregated across time but reported for all routes, useful?  What additional data from the Uber Movement website can you export to better your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf88fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd8e5c3e",
   "metadata": {},
   "source": [
    "## Question 5c\n",
    "\n",
    "Explore other modeling aspects and/or temporal information. You are free to relate this to your hypothesis or not. Please expand into multiple parts that logically separate and break down your modeling work!\n",
    "\n",
    "**Example**\n",
    "\n",
    "For example, explore change across time, before and after the lockdown: (a) train and evaluate on *pre*-lockdown traffic travel times for that route; and (b) evaluate your model on *post*-lockdown traffic patterns.\n",
    "How would you correct your model for a more accurate post-lockdown traffic predictor? *The above is just a suggestion. You may pick any topic you find interesting.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648a468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc3e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "400dba85",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d058c6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a248128",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e244f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732614ed",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
