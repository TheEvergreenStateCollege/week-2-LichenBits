{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw8.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0f9b2de18190d9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Homework 8: Understanding Cook County Home Value Appraisals\n",
    "\n",
    "## Due Date: Thursday, October 21st, 11:59 PM PDT\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the collaborators cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In Homework 8 and Homework 9, we will go through the iterative process of specifying, fitting, and analyzing the performance of a  model.  \n",
    "\n",
    "In the first portion of the assignment, we will guide you through some basic exploratory data analysis (EDA), laying out the thought process that leads to certain modeling decisions. Next, you will be adding a few new features to the dataset, cleaning the data as well in the process.\n",
    "\n",
    "In Homework 9, you will specify and fit a linear model to a few features of the housing data to predict housing prices. Finally, we will analyze the error of the model and brainstorm ways to improve the model's performance.\n",
    "\n",
    "\n",
    "## Score Breakdown\n",
    "\n",
    "Question | Part | Points\n",
    "----|----|----\n",
    "0 | - | 1\n",
    "1 | 1 | 1\n",
    "1 | 2 | 1\n",
    "1 | 3 | 1\n",
    "1 | 4 | 1\n",
    "2 | 1 | 1\n",
    "2 | 2 | 1\n",
    "3 | 1 | 3\n",
    "3 | 2 | 1\n",
    "3 | 3 | 1\n",
    "4 | - | 2\n",
    "5 | 1 | 1\n",
    "5 | 2 | 2\n",
    "5 | 3 | 2\n",
    "6 | 1 | 1\n",
    "6 | 2 | 2\n",
    "6 | 3 | 1\n",
    "6 | 4 | 2\n",
    "6 | 5 | 1\n",
    "7 | 1 | 1\n",
    "7 | 2 | 2\n",
    "Total | - | 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62cfd21463535cac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from ds100_utils import run_linear_regression_test\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f68729731e7fe39d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# The Cook County Assessor's Office\n",
    "\n",
    "The dataset you’ll be working with comes from the Cook County Assessor’s Office (CCAO) in Illinois, a government institution that determines property taxes across most of Chicago’s metropolitan area and its nearby suburbs. In the United States, all property owners are required to pay property taxes, which are then used to fund public services including education, road maintenance, and sanitation. These property tax assessments are based on property values estimated using statistical models that consider multiple factors, such as real estate value and construction cost.\n",
    "\n",
    "This system, however, is not without flaws. In late 2017, a lawsuit was filed against the office of Cook County Assessor Joseph Berrios for producing [“racially discriminatory assessments and taxes.\"](https://www.chicagotribune.com/politics/ct-cook-county-board-assessor-berrios-met-20170718-story.html) The lawsuit included claims that the assessor’s office undervalued high-priced homes and overvalued low-priced homes, creating a visible divide along racial lines: Wealthy homeowners, who were typically white, [paid less in property taxes](https://www.clccrul.org/bpnc-v-berrios-facts?rq=berrios), whereas [working-class, non-white homeowners paid more](https://www.chicagotribune.com/news/breaking/ct-cook-county-assessor-berrios-sued-met-20171214-story.html).\n",
    "\n",
    "The Chicago Tribune's four-part series, [\"The Tax Divide\"](https://www.chicagotribune.com/investigations/ct-tax-divide-investigation-20180425-storygallery.html), delves into how this was uncovered: After \"compiling and analyzing more than 100 million property tax records from the years 2003 through 2015, along with thousands of pages of documents, then vetting the findings with top experts in the field,\" they discovered that \"residential assessments [had] been so far off the mark for so many years.\" You can read more about their investigation [here](https://apps.chicagotribune.com/news/watchdog/cook-county-property-tax-divide/assessments.html).\n",
    "\n",
    "Additionally, the discrimination described in the lawsuit is built on a much deeper history - including the practice of redlining in Chicago. Though this is by no means a comprehensive history, Merriam-Webster defines redlining as the \"withholdding of home-loan funds or insurance from neighborhoods considered poor economic risks.\" The neighborhoods in this category, however, were typically comprised of Black communities; redlining, then, systemically prevented Black residents from moving into other neighborhoods and improving their current homes by denying them the financial assistance that white residents were afforded. Though the Fair Housing Act of 1968 outlawed redlining, its [impacts](https://www.washingtonpost.com/news/wonk/wp/2018/03/28/redlining-was-banned-50-years-ago-its-still-hurting-minorities-today/) and [practices](https://www.chicagotribune.com/business/ct-biz-modern-day-redlining-20180215-story.html) are still present today.\n",
    "\n",
    "This context is vital to understanding how the Cook County Residential Sales Data - the dataset you'll be working with - was procured. This introduction aims to address how legacies of racial discrimination practices can be encoded within data, as well as consider how they might influence modeling choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 0\n",
    "\n",
    "In what ways were the CCAO's property assessments discriminatory in late 2017?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q0\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# The Data\n",
    "\n",
    "The [CCAO dataset](https://datacatalog.cookcountyil.gov/Property-Taxation/Archive-Cook-County-Assessor-s-Residential-Sales-D/5pge-nu6u) consists of over 500 thousand records describing houses sold in Cook County in recent years (new records are still coming in every week!). The data set we will be working with has 61 features in total. An explanation of each variable can be found in the included `codebook.txt` file. Some of the columns have been filtered out to ensure this assignment doesn't become overly long when dealing with data cleaning and formatting. For more context about this dataset please see [Lecture 15](https://ds100.org/su21/lecture/lec15/).\n",
    "\n",
    "The data are split into training and test sets with 204792 and 68264 observations, respectively.\n",
    "\n",
    "Let's first extract the data from the `cook_county_data.zip`. Notice we didn't leave the `csv` files directly in the directory because they take up too much space without some prior compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('cook_county_data.zip') as item:\n",
    "    item.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8fea30adc9d489b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"cook_county_train.csv\", index_col='Unnamed: 0')\n",
    "test_data = pd.read_csv(\"cook_county_test.csv\", index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d6d509b6e854e10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "As a good sanity check, we should at least verify that the data shape matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c841a2de55691502",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 204792 observations and 62 features in training data\n",
    "assert training_data.shape == (204792, 62)\n",
    "# 68264 observations and 61 features in test data\n",
    "assert test_data.shape == (68264, 61)\n",
    "# Sale Price is provided in the training data\n",
    "assert 'Sale Price' in training_data.columns.values\n",
    "# Sale Price is hidden in the test data\n",
    "assert 'Sale Price' not in test_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce9acc2f62c96e59",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The next order of business is getting a feel for the variables in our data.  The Cook County data set contains information that typical homebuyers would want to know.  A more detailed description of each variable is included in `codebook.txt` (in the same directory as this notebook).  **You should take some time to familiarize yourself with the codebook before moving forward.**\n",
    "\n",
    "Let's take a quick look at all the current columns in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e60a7a0cda5eecf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['Description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'(\\d+) of which are bedrooms'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# Part 1: Contextualizing the Data\n",
    "\n",
    "Let's try to understand the background of our dataset before diving into a full-scale analysis. \n",
    "\n",
    "Prior to the open data initiative and even prior to the assessment modeling initiative, Cook County’s assessor office received much of their data for assessments from their relationships with [“local elected officials, community leaders, real estate professionals and other citizens knowledgeable about real estate in the area.”](https://www.cookcountyassessor.com/about-cook-county-assessors-office) Because CCAO field inspectors cannot enter homes to gather data, this information must be gathered through either curbside observations or real estate records.\n",
    "\n",
    "You can read more about data collection in the CCAO’s [Residential Data Integrity Preliminary Report](https://gitlab.com/ccao-data-science---modeling/ccao_sf_cama_dev/-/blob/master/documentation/Preliminary%20Report%20on%20Data%20Integrity%20June%207,%202019.pdf).\n",
    "\n",
    "## Question 1\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Take a moment to assess the granularity of this dataset. What does each row represent?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Part 2\n",
    "\n",
    "Name a feature that isn't listed in this dataset but may be useful for predicting sales values. What insights could this feature provide? How might it increase or decrease a home’s sales value?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Part 3\n",
    "Let’s take a look at the `Site Desirability` column. What do the column’s values represent? Does the codebook provide sufficient guidelines as to how a property's `Site Desirability` is determined? Why or why not?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Just by looking at the feature and its description, we can tell that `Site Desirability` is highly discretionary - that is, it relies on an individual's interpretation, which is informed by historically and socially-determined practices. And in this context, the individual in question would be a real estate agent or assessor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Part 4\n",
    "Beyond a home’s internal characteristics (such as number of rooms, bathrooms, etc.), describe a factor that might influence whether a home is desirable, and elaborate why. Think from the perspective of a real estate agent - i.e. what would an agent market to potential buyers and why?\n",
    "\n",
    "**Hint:** Consider writing about characteristics related to a home’s location and its proximity to other places.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "When examining your data, it’s important to consider who collects the data in order to understand the assumptions and perspectives built into it. Here, the idea of desirable properties is influenced by what the real estate industry - a source of expertise in home valuations - deems popular with its market. These human choices about value are shaped by the real estate agents' expertise acquired through their professional training and experience. From a seller's perspective, this expertise also makes the agent's valuations legitimate and authoritative in a way that's difficult to contest. As a result, a form of professional bias enters into the valuation process, and though this bias isn’t inherently bad, we’ll delve deeper into how it interacts with, and often reinforces, structural inequity.\n",
    "\n",
    "To continue using `Site Desirability` as an example, let’s say that proximity to high-ranking schools adds to a home’s desirability. Because schools are largely funded by property taxes, high-ranking schools are typically located near homes in higher-income neighborhoods. Comparatively, homes in lower-income neighborhoods - with families predominantly from Hispanic and Black communities - would be deemed “less desirable” because they would not feed into high-ranking schools, further devaluing homes in lower-income neighborhoods.\n",
    "\n",
    "In this way, `Site Desirability` acts as a proxy for sensitive attributes, such as the racial distribution of a neighborhood. Although it does not explicitly name these attributes, `Site Desirability` ultimately encodes the broader socioeconomic and racial context of a home’s surrounding community. And because real estate agents affirm their classifications of `Site Desirability` based on their expertise, structural inequity is further perpetuated as this bias is embedded in the data used to generate housing valuation models.\n",
    "\n",
    "Understanding your dataset provides a lot of insight into how models might incorporate bias from the very beginning. A data scientist with this awareness would not only identify sources of bias, but also aim to intentionally address these biases in their data analyses, as well as the outputs and recommendations based on these analyses. As we progress through this homework, keep these perspectives on bias and expertise in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba0f6926b0dafefb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 2: Exploratory Data Analysis\n",
    "\n",
    "In this section, we will make a series of exploratory visualizations and interpret them.\n",
    "\n",
    "Note that we will perform EDA on the **training data** so that information from the test data does not influence our modeling decisions.\n",
    "\n",
    "### Sale Price\n",
    "We begin by examining the distribution of our target variable `SalePrice`.  At the same time, we also take a look at some descriptive statistics of this variable. We have provided the following helper method `plot_distribution` that you can use to visualize the distribution of the `SalePrice` using both the histogram and the box plot at the same time. Run the following 2 cells and describe what you think is wrong with the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-15d483a695655cea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_distribution(data, label):\n",
    "    fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "    sns.distplot(\n",
    "        data[label], \n",
    "        ax=axs[0]\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        data[label],\n",
    "        width=0.3, \n",
    "        ax=axs[1],\n",
    "        showfliers=False,\n",
    "    )\n",
    "\n",
    "    # Align axes\n",
    "    spacer = np.max(data[label]) * 0.05\n",
    "    xmin = np.min(data[label]) - spacer\n",
    "    xmax = np.max(data[label]) + spacer\n",
    "    axs[0].set_xlim((xmin, xmax))\n",
    "    axs[1].set_xlim((xmin, xmax))\n",
    "\n",
    "    # Remove some axis text\n",
    "    axs[0].xaxis.set_visible(False)\n",
    "    axs[0].yaxis.set_visible(False)\n",
    "    axs[1].yaxis.set_visible(False)\n",
    "\n",
    "    # Put the two plots together\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "\n",
    "    # Adjust boxplot fill to be white\n",
    "    axs[1].artists[0].set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(training_data, label='Sale Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 2\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Identify one issue with the visualization above and briefly describe one way to overcome it. You may also want to try running `training_data['Sale Price'].describe()` in a different cell to see some specific summary statistics on the distribution of the target variable. Make sure to delete the cell afterwards as the autograder may not work otherwise.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Part 2\n",
    "\n",
    "To zoom in on the visualization of most households, we will focus only on a subset of `Sale Price` for this assignment. In addition, it may be a good idea to apply log transformation to `Sale Price`. In the cell below, reassign `training_data` to a new dataframe that is the same as the original one **except with the following changes**:\n",
    "\n",
    "- `training_data` should contain only households whose price is at least $500.\n",
    "- `training_data` should contain a new `Log Sale Price` column that contains the log-transformed sale prices.\n",
    "\n",
    "**Note**: This also implies from now on, our target variable in the model will be the log transformed sale prices from the column `Log Sale Price`. \n",
    "\n",
    "**Note**: You should **NOT** remove the original column `Sale Price` as it will be helpful for later questions.\n",
    "\n",
    "*To ensure that any error from this part does not propagate to later questions, there will be no hidden test here.*\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new distribution plot on the log-transformed sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(training_data, label='Log Sale Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-592d5f41ebd67ee2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 3\n",
    "\n",
    "### Part 1\n",
    "To check your understanding of the graph and summary statistics above, answer the following `True` or `False` questions:\n",
    "\n",
    "1. The distribution of `Log Sale Price` in the training set is left-skewed.\n",
    "1. The mean of `Log Sale Price` in the training set is greater than the median.\n",
    "1. At least 25% of the houses in the training set sold for more than \\$200,000.00.\n",
    "\n",
    "*The provided tests for this question do not confirm that you have answered correctly; only that you have assigned each variable to `True` or `False`.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "points:\n",
    "- 0\n",
    "- 1\n",
    "- 1\n",
    "- 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# These should be True or False\n",
    "q3statement1 = ...\n",
    "q3statement2 = ...\n",
    "q3statement3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e22aac9b45f88e3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part 2\n",
    "\n",
    "Next, we want to explore if any there is any correlation between `Log Sale Price` and the total area occupied by the household. The `codebook.txt` file tells us the column `Building Square Feet` should do the trick -- it measures \"(from the exterior) the total area, in square feet, occupied by the building\".\n",
    "\n",
    "Before creating this jointplot however, let's also apply a log transformation to the `Building Square Feet` column.\n",
    "\n",
    "In the following cell, create a new column `Log Building Square Feet` in our training data that contains the log transformed area occupied by each household. \n",
    "\n",
    "**You should NOT remove the original `Building Square Feet` column this time as it will be used for later questions**. \n",
    "\n",
    "*To ensure that any errors from this part do not propagate to later questions, there will be no hidden tests here.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Part 3\n",
    "\n",
    "As shown below, we created a joint plot with `Log Building Square Feet` on the x-axis, and `Log Sale Price` on the y-axis. In addition, we fit a simple linear regression line through the bivariate scatter plot in the middle.\n",
    "\n",
    "Based on the following plot, does there exist a correlation between `Log Sale Price` and `Log Building Square Feet`? Would `Log Building Square Feet` make a good candidate as one of the features for our model?\n",
    "\n",
    "![Joint Plot](images/q2p3_jointplot.png)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3c\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf7fe5dcd37df6f9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 3\n",
    "\n",
    "Continuing from the previous part, as you explore the data set, you might still run into more outliers that prevent you from creating a clear visualization or capturing the trend of the majority of the houses. \n",
    "\n",
    "For this assignment, we will work to remove these outliers from the data as we run into them. Write a function `remove_outliers` that removes outliers from a data set based off a threshold value of a variable.  For example, `remove_outliers(training_data, 'Building Square Feet', upper=8000)` should return a data frame with only observations that satisfy `Building Square Feet` less than or equal to 8000.\n",
    "\n",
    "*The provided tests check that training_data was updated correctly, so that future analyses are not corrupted by a mistake. However, the provided tests do not check that you have implemented remove_outliers correctly so that it works with any data, variable, lower, and upper bound.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9186ec2ca053d0aa",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_outliers(data, variable, lower=-np.inf, upper=np.inf):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): the table to be filtered\n",
    "      variable (string): the column with numerical outliers\n",
    "      lower (numeric): observations with values lower than this will be removed\n",
    "      upper (numeric): observations with values higher than this will be removed\n",
    "    \n",
    "    Output:\n",
    "      a data frame with outliers removed\n",
    "      \n",
    "    Note: This function should not change mutate the contents of data.\n",
    "    \"\"\"  \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Part 3: Feature Engineering\n",
    "\n",
    "In this section we will walk you through a few feature engineering techniques. \n",
    "\n",
    "### Bedrooms\n",
    "\n",
    "Let's start simple by extracting the total number of bedrooms as our first feature for the model. You may notice that the `Bedrooms` column doesn't actually exist in the original dataframe! Instead, it is part of the `Description` column.\n",
    "\n",
    "## Question 5\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Let's take a closer look at the `Description` column first. Compare the description across a few rows together at the same time. For the following list of variables, how many of them can be extracted from the `Description` column? Assign your answer as an integer to the variable `q4a`.\n",
    "- The date the property was sold on\n",
    "- The number of stories the property contains\n",
    "- The previous owner of the property\n",
    "- The address of the property\n",
    "- The number of garages the property has\n",
    "- The total number of rooms inside the property\n",
    "- The total number of bedrooms inside the property\n",
    "- The total number of bathrooms inside the property\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5a\n",
    "points:\n",
    "- 0\n",
    "- 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5a = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part 2\n",
    "\n",
    "Write a function `add_total_bedrooms(data)` that returns a copy of `data` with an additional column called `Bedrooms` that contains the total number of bathrooms (as integers) for each house. **Treat missing values as zeros if necessary**. Remember that you can make use of vectorized code here; you shouldn't need any `for` statements. \n",
    "\n",
    "**Hint**: You should consider inspecting the `Description` column to figure out if there is any general structure within the text. Once you have noticed a certain pattern, you are set with the power of Regex!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5b\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_total_bedrooms(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing at least the Description column.\n",
    "    \"\"\"\n",
    "    with_rooms = data.copy()\n",
    "    ...\n",
    "    return with_rooms\n",
    "\n",
    "training_data = add_total_bedrooms(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Part 3\n",
    "\n",
    "Create a visualization that clearly and succintly shows if there exists an association between  `Bedrooms` and `Log Sale Price`. A good visualization should satisfy the following requirements:\n",
    "- It should avoid overplotting.\n",
    "- It should have clearly labeled axes and succinct title.\n",
    "- It should convey the strength of the correlation between the sale price and the number of rooms. \n",
    "\n",
    "**Hint**: A direct scatter plot of the sale price against the number of rooms for all of the households in our training data might risk overplotting.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5c\n",
    "points: 2\n",
    "manual: True\n",
    "format: image\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the relationship between neighborhood and sale prices of the houses in our data set.\n",
    "Notice that currently we don't have the actual names for the neighborhoods. Instead we will use a similar column `Neighborhood Code` (which is a numerical encoding of the actual neighborhoods by the Assessment office)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part 1\n",
    "\n",
    "Before creating any visualization, let's quickly inspect how many different neighborhoods we are dealing with.\n",
    "\n",
    "Assign the variable `num_neighborhoods` with the total number of neighborhoods in `training_data`. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighborhoods = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part  2\n",
    "\n",
    "If we try directly plotting the distribution of `Log Sale Price` for all of the households in each neighborhood using the `plot_categorical` function from the next cell, we would get the following visualization.\n",
    "![overplot](images/q5p2_catplot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_categorical(neighborhoods, data, with_filter=True):\n",
    "    if not with_filter:\n",
    "        neighborhoods = data\n",
    "    fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "    sns.boxplot(\n",
    "        x='Neighborhood Code',\n",
    "        y='Log Sale Price',\n",
    "        data=neighborhoods.sort_values('Neighborhood Code'),\n",
    "        ax=axs[0],\n",
    "    )\n",
    "\n",
    "    sns.countplot(\n",
    "        x='Neighborhood Code',\n",
    "        data=neighborhoods.sort_values('Neighborhood Code'),\n",
    "        ax=axs[1],\n",
    "    )\n",
    "\n",
    "    # Draw median price\n",
    "    axs[0].axhline(\n",
    "        y=data['Log Sale Price'].median(), \n",
    "        color='red',\n",
    "        linestyle='dotted'\n",
    "    )\n",
    "\n",
    "    # Label the bars with counts\n",
    "    for patch in axs[1].patches:\n",
    "        x = patch.get_bbox().get_points()[:, 0]\n",
    "        y = patch.get_bbox().get_points()[1, 1]\n",
    "        axs[1].annotate(f'{int(y)}', (x.mean(), y), ha='center', va='bottom')\n",
    "\n",
    "    # Format x-axes\n",
    "    axs[1].set_xticklabels(axs[1].xaxis.get_majorticklabels(), rotation=90)\n",
    "    axs[0].xaxis.set_visible(False)\n",
    "\n",
    "    # Narrow the gap between the plots\n",
    "    plt.subplots_adjust(hspace=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Oh no, looks like we have run into the problem of overplotting again! \n",
    "\n",
    "You might have noticed that the graph is overplotted because **there are actually quite a few neighborhoods in our dataset**! For the clarity of our visualization, we will have to zoom in again on a few of them. The reason for this is our visualization will become quite cluttered with a super dense x-axis.\n",
    "\n",
    "Assign the variable `in_top_20_neighborhoods` to a copy of `training_data` that contains only neighborhoods with the top 20 number of buildings. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_top_20_neighborhoods = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create another of the distribution of sale price within in each neighborhood again, but this time with a narrower focus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical(neighborhoods=in_top_20_neighborhoods, data=training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Part 3\n",
    "\n",
    "It looks a lot better now than before, right? Based on the plot above, what can be said about the relationship between the houses' `Log Sale Price` and their neighborhoods?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6c\n",
    "points: 1\n",
    "manual: True\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Part 4\n",
    "\n",
    "One way we can deal with the lack of data from some neighborhoods is to create a new feature that bins neighborhoods together.  Let's categorize our neighborhoods in a crude way: we'll take the top 3 neighborhoods measured by median `Log Sale Price` and identify them as \"expensive neighborhoods\"; the other neighborhoods are not marked.\n",
    "\n",
    "Write a function that returns list of the neighborhood codes of the top `n` most pricy neighborhoods as measured by our choice of aggregating function.  For example, in the setup above, we would want to call `find_expensive_neighborhoods(training_data, 3, np.median)` to find the top 3 neighborhoods measured by median `Log Sale Price`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6d\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_expensive_neighborhoods(data, n=3, metric=np.median):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): should contain at least a string-valued Neighborhood\n",
    "        and a numeric 'Sale Price' column\n",
    "      n (int): the number of top values desired\n",
    "      metric (function): function used for aggregating the data in each neighborhood.\n",
    "        for example, np.median for median prices\n",
    "    \n",
    "    Output:\n",
    "      a list of the the neighborhood codes of the top n highest-priced neighborhoods as measured by the metric function\n",
    "    \"\"\"\n",
    "    neighborhoods = ...\n",
    "    \n",
    "    # This makes sure the final list contains the generic int type used in Python3, not specific ones used in numpy.\n",
    "    return [int(code) for code in neighborhoods]\n",
    "\n",
    "expensive_neighborhoods = find_expensive_neighborhoods(training_data, 3, np.median)\n",
    "expensive_neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part 5\n",
    "We now have a list of neighborhoods we've deemed as higher-priced than others.  Let's use that information to write a function `add_expensive_neighborhood` that adds a column `in_expensive_neighborhood` which takes on the value 1 if the house is part of `expensive_neighborhoods` and the value 0 otherwise. This type of variable is known as an indicator variable.\n",
    "\n",
    "**Hint:** [`pd.Series.astype`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Series.astype.html) may be useful for converting True/False values to integers.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6e\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_in_expensive_neighborhood(data, neighborhoods):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Neighborhood Code' column with values\n",
    "        found in the codebook\n",
    "      neighborhoods (list of strings): strings should be the names of neighborhoods\n",
    "        pre-identified as expensive\n",
    "    Output:\n",
    "      data frame identical to the input with the addition of a binary\n",
    "      in_expensive_neighborhood column\n",
    "    \"\"\"\n",
    "    data['in_expensive_neighborhood'] = ...\n",
    "    return data\n",
    "\n",
    "expensive_neighborhoods = find_expensive_neighborhoods(training_data, 3, np.median)\n",
    "training_data = add_in_expensive_neighborhood(training_data, expensive_neighborhoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "In the following question, we will take a closer look at the `Roof Material` feature of the dataset and examine how we can incorporate categorical features into our linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part 1\n",
    "\n",
    "If we look at the codebook carefully, we can see that the Assessor's Office uses the following mapping for the numerical values in the `Roof Material` column.\n",
    "```\n",
    "Central Heating (Nominal): \n",
    "\n",
    "       1\tShingle/Asphalt\n",
    "       2\tTar&Gravel\n",
    "       3\tSlate\n",
    "       4\tShake\n",
    "       5    Tile\n",
    "       6    Other\n",
    "```\n",
    "\n",
    "Write a function `substitute_roof_material` that replaces each numerical value in `Roof Material` with their corresponding roof material. Your function should return a new DataFrame, not modify the existing DataFrame.\n",
    "\n",
    "**Hint**: the [DataFrame.replace](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html) method may be useful here.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7a\n",
    "points: 1\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_roof_material(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Roof Material' column.  Its values\n",
    "                         should be limited to those found in the codebook\n",
    "    Output:\n",
    "      data frame identical to the input except with a refactored 'Roof Material' column\n",
    "    \"\"\"\n",
    "    ...\n",
    "    return data\n",
    "    \n",
    "training_data = substitute_roof_material(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Part 2\n",
    "\n",
    "#### An Important Note on One Hot Encoding \n",
    "\n",
    "Unfortunately, simply fixing these missing values isn't sufficient for using `Roof Material` in our model.  Since `Roof Material` is a categorical variable, we will have to one-hot-encode the data.  Notice in the example code below that we have to pre-specify the categories.  Why? Imagine what would happen if we automatically generated the categories only from the training data.  What would happen if the testing data contained a category not found in the training set?  For more information on categorical data in pandas, refer to this [link](https://pandas-docs.github.io/pandas-docs-travis/user_guide/categorical.html).\n",
    "\n",
    "Complete the following function `ohe_roof_material` that returns a dataframe with the new column one-hot-encoded on the roof material of the household. These new columns should have the form `x0_MATERIAL`.\n",
    "\n",
    "**Note**: You should **avoid using `pd.get_dummies`** in your solution as it will remove your original column and is therefore not as reusable as your constructed data preprocessing pipeline. Instead, you can one-hot-encode one column into multiple columns **using Scikit-learn's [One Hot Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)**.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7b\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def ohe_roof_material(data):\n",
    "    \"\"\"\n",
    "    One-hot-encodes roof material.  New columns are of the form x0_MATERIAL.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "training_data = ohe_roof_material(training_data)\n",
    "training_data.filter(regex='^x0').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You have finished Homework 8!\n",
    "\n",
    "In Homework 9, you will use the features you engineered in this homework to build a linear model to predict home prices. In the meantime, consider the implications of your work so far: Given the history of racial discrimination in housing policy and property taxation, defining what a fair assessment entails is no easy feat. In addition to historical context, these assessments are a product of choices made at every level of the assessment process, from data collection to modeling. And the humans who make these choices - real estate agents, data scientists, county assessors, and, in this homework and the next, you - must understand the inputs to and consider the impacts of these decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
